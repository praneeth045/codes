{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61271fe2-8acb-4247-885b-f13439e69261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: no, Feature: age_31...40, Density: [-0.22579135 -0.22579135 -2.22579135 -0.22579135 -0.22579135 -0.22579135\n",
      " -2.22579135 -0.22579135 -0.22579135 -0.22579135 -0.22579135 -2.22579135\n",
      " -2.22579135 -0.22579135]\n",
      "Class: no, Feature: age_<=30, Density: [-0.65023423 -0.65023423 -0.95726122 -0.95726122 -0.95726122 -0.95726122\n",
      " -0.95726122 -0.65023423 -0.65023423 -0.95726122 -0.65023423 -0.95726122\n",
      " -0.95726122 -0.95726122]\n",
      "Class: no, Feature: age_>40, Density: [-0.65023423 -0.65023423 -0.65023423 -0.95726122 -0.95726122 -0.95726122\n",
      " -0.65023423 -0.65023423 -0.65023423 -0.95726122 -0.65023423 -0.65023423\n",
      " -0.65023423 -0.95726122]\n",
      "Class: no, Feature: income_high, Density: [-0.95726122 -0.95726122 -0.95726122 -0.65023423 -0.65023423 -0.65023423\n",
      " -0.65023423 -0.65023423 -0.65023423 -0.65023423 -0.65023423 -0.65023423\n",
      " -0.95726122 -0.65023423]\n",
      "Class: no, Feature: income_low, Density: [-0.41566086 -0.41566086 -0.41566086 -0.41566086 -1.40257636 -1.40257636\n",
      " -1.40257636 -0.41566086 -1.40257636 -0.41566086 -0.41566086 -0.41566086\n",
      " -0.41566086 -0.41566086]\n",
      "Class: no, Feature: income_medium, Density: [-0.65023423 -0.65023423 -0.65023423 -0.95726122 -0.65023423 -0.65023423\n",
      " -0.65023423 -0.95726122 -0.65023423 -0.95726122 -0.95726122 -0.95726122\n",
      " -0.65023423 -0.95726122]\n",
      "Class: no, Feature: student_no, Density: [-0.41566086 -0.41566086 -0.41566086 -0.41566086 -1.40257636 -1.40257636\n",
      " -1.40257636 -0.41566086 -1.40257636 -1.40257636 -1.40257636 -0.41566086\n",
      " -1.40257636 -0.41566086]\n",
      "Class: no, Feature: student_yes, Density: [-0.41566086 -0.41566086 -0.41566086 -0.41566086 -1.40257636 -1.40257636\n",
      " -1.40257636 -0.41566086 -1.40257636 -1.40257636 -1.40257636 -0.41566086\n",
      " -1.40257636 -0.41566086]\n",
      "Class: no, Feature: credit_rating_excellent, Density: [-0.95726122 -0.65023423 -0.95726122 -0.95726122 -0.95726122 -0.65023423\n",
      " -0.65023423 -0.95726122 -0.95726122 -0.95726122 -0.65023423 -0.65023423\n",
      " -0.95726122 -0.65023423]\n",
      "Class: no, Feature: credit_rating_fair, Density: [-0.95726122 -0.65023423 -0.95726122 -0.95726122 -0.95726122 -0.65023423\n",
      " -0.65023423 -0.95726122 -0.95726122 -0.95726122 -0.65023423 -0.65023423\n",
      " -0.95726122 -0.65023423]\n",
      "Class: yes, Feature: age_31...40, Density: [-0.71077938 -0.71077938 -0.88042824 -0.71077938 -0.71077938 -0.71077938\n",
      " -0.88042824 -0.71077938 -0.71077938 -0.71077938 -0.71077938 -0.88042824\n",
      " -0.88042824 -0.71077938]\n",
      "Class: yes, Feature: age_<=30, Density: [-1.34211049 -1.34211049 -0.43916741 -0.43916741 -0.43916741 -0.43916741\n",
      " -0.43916741 -1.34211049 -1.34211049 -0.43916741 -1.34211049 -0.43916741\n",
      " -0.43916741 -0.43916741]\n",
      "Class: yes, Feature: age_>40, Density: [-0.56577997 -0.56577997 -0.56577997 -1.08485888 -1.08485888 -1.08485888\n",
      " -0.56577997 -0.56577997 -0.56577997 -1.08485888 -0.56577997 -0.56577997\n",
      " -0.56577997 -1.08485888]\n",
      "Class: yes, Feature: income_high, Density: [-1.34211049 -1.34211049 -1.34211049 -0.43916741 -0.43916741 -0.43916741\n",
      " -0.43916741 -0.43916741 -0.43916741 -0.43916741 -0.43916741 -0.43916741\n",
      " -1.34211049 -0.43916741]\n",
      "Class: yes, Feature: income_low, Density: [-0.56577997 -0.56577997 -0.56577997 -0.56577997 -1.08485888 -1.08485888\n",
      " -1.08485888 -0.56577997 -1.08485888 -0.56577997 -0.56577997 -0.56577997\n",
      " -0.56577997 -0.56577997]\n",
      "Class: yes, Feature: income_medium, Density: [-0.71077938 -0.71077938 -0.71077938 -0.88042824 -0.71077938 -0.71077938\n",
      " -0.71077938 -0.88042824 -0.71077938 -0.88042824 -0.88042824 -0.88042824\n",
      " -0.71077938 -0.88042824]\n",
      "Class: yes, Feature: student_no, Density: [-1.08485888 -1.08485888 -1.08485888 -1.08485888 -0.56577997 -0.56577997\n",
      " -0.56577997 -1.08485888 -0.56577997 -0.56577997 -0.56577997 -1.08485888\n",
      " -0.56577997 -1.08485888]\n",
      "Class: yes, Feature: student_yes, Density: [-1.08485888 -1.08485888 -1.08485888 -1.08485888 -0.56577997 -0.56577997\n",
      " -0.56577997 -1.08485888 -0.56577997 -0.56577997 -0.56577997 -1.08485888\n",
      " -0.56577997 -1.08485888]\n",
      "Class: yes, Feature: credit_rating_excellent, Density: [-0.56577997 -1.08485888 -0.56577997 -0.56577997 -0.56577997 -1.08485888\n",
      " -1.08485888 -0.56577997 -0.56577997 -0.56577997 -1.08485888 -1.08485888\n",
      " -0.56577997 -1.08485888]\n",
      "Class: yes, Feature: credit_rating_fair, Density: [-0.56577997 -1.08485888 -0.56577997 -0.56577997 -0.56577997 -1.08485888\n",
      " -1.08485888 -0.56577997 -0.56577997 -0.56577997 -1.08485888 -1.08485888\n",
      " -0.56577997 -1.08485888]\n",
      "\n",
      "Features and Classes with Zero Densities:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KernelDensity\n",
    " \n",
    "# Load the dataset from the CSV file\n",
    "df = pd.read_csv('lab_4.csv')\n",
    " \n",
    "# Select features and target variable\n",
    "features = df[['age', 'income', 'student', 'credit_rating']]\n",
    "target = df['buys_computer']\n",
    " \n",
    "# Encode categorical variables\n",
    "features_encoded = pd.get_dummies(features)\n",
    " \n",
    "# Create a dictionary to store class conditional densities\n",
    "class_conditional_densities = {}\n",
    " \n",
    "# Calculate class conditional densities for each feature\n",
    "for class_label in target.unique():\n",
    "    # Select instances for the current class\n",
    "    instances = features_encoded[target == class_label]\n",
    "    \n",
    "    # Calculate kernel density estimate for each feature\n",
    "    for feature in features_encoded.columns:\n",
    "        kde = KernelDensity(bandwidth=0.5)  # You may need to adjust the bandwidth\n",
    "        kde.fit(instances[[feature]])\n",
    "        class_conditional_densities[(class_label, feature)] = kde\n",
    " \n",
    "# Display the class conditional densities\n",
    "for key, kde in class_conditional_densities.items():\n",
    "    print(f\"Class: {key[0]}, Feature: {key[1]}, Density: {kde.score_samples(features_encoded[[key[1]]])}\")\n",
    " \n",
    "# Check for zero values\n",
    "zero_densities = [(class_label, feature) for (class_label, feature), kde in class_conditional_densities.items()\n",
    "                  if any(density == float('-inf') for density in kde.score_samples(features_encoded[[feature]]))]\n",
    " \n",
    "# Display features and classes with zero densities\n",
    "print(\"\\nFeatures and Classes with Zero Densities:\")\n",
    "print(zero_densities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0b3bfb6-594f-4dda-aaaa-65ad3abf4aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "<=30       0.357143\n",
      ">40        0.357143\n",
      "31...40    0.285714\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the data from the CSV file\n",
    "data = pd.read_csv('lab_4.csv')\n",
    "\n",
    "# Count the number of occurrences of each class\n",
    "class_counts = data['age'].value_counts()\n",
    "\n",
    "# Calculate the prior probability for each class\n",
    "prior_probabilities = class_counts / len(data)\n",
    "\n",
    "# Print the prior probabilities\n",
    "print(prior_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28e65b40-110b-4f5c-8286-84086dfd134c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "income\n",
      "medium    0.428571\n",
      "high      0.285714\n",
      "low       0.285714\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the data from the CSV file\n",
    "data = pd.read_csv('lab_4.csv')\n",
    "\n",
    "# Count the number of occurrences of each class\n",
    "class_counts = data['income'].value_counts()\n",
    "\n",
    "# Calculate the prior probability for each class\n",
    "prior_probabilities = class_counts / len(data)\n",
    "\n",
    "# Print the prior probabilities\n",
    "print(prior_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "981589b4-7df3-407f-8bb4-7ff11c4bd670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student\n",
      "no     0.5\n",
      "yes    0.5\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the data from the CSV file\n",
    "data = pd.read_csv('lab_4.csv')\n",
    "\n",
    "# Count the number of occurrences of each class\n",
    "class_counts = data['student'].value_counts()\n",
    "\n",
    "# Calculate the prior probability for each class\n",
    "prior_probabilities = class_counts / len(data)\n",
    "\n",
    "# Print the prior probabilities\n",
    "print(prior_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50cdc915-12f4-4f1b-bdaf-56854456222b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "credit_rating\n",
      "fair         0.571429\n",
      "excellent    0.428571\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the data from the CSV file\n",
    "data = pd.read_csv('lab_4.csv')\n",
    "\n",
    "# Count the number of occurrences of each class\n",
    "class_counts = data['credit_rating'].value_counts()\n",
    "\n",
    "# Calculate the prior probability for each class\n",
    "prior_probabilities = class_counts / len(data)\n",
    "\n",
    "# Print the prior probabilities\n",
    "print(prior_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c823212b-f595-4bee-be3f-ef58ffc321ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buys_computer\n",
      "yes    0.642857\n",
      "no     0.357143\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the data from the CSV file\n",
    "data = pd.read_csv('lab_4.csv')\n",
    "\n",
    "# Count the number of occurrences of each class\n",
    "class_counts = data['buys_computer'].value_counts()\n",
    "\n",
    "# Calculate the prior probability for each class\n",
    "prior_probabilities = class_counts / len(data)\n",
    "\n",
    "# Print the prior probabilities\n",
    "print(prior_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ed52c0e-c9d6-477f-80b6-cc6621e8660e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.6764100579553458\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Read the data from the CSV file\n",
    "data = pd.read_csv('lab_4.csv')\n",
    "\n",
    "# Create a contingency table for the four features\n",
    "contingency_table = pd.crosstab(data['age'], [data['income'], data['student'], data['credit_rating']])\n",
    "\n",
    "# Perform the chi-square test of independence\n",
    "chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# Print the p-value\n",
    "print(\"p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08f8ad7b-56ed-4921-b6c5-c69e6d025670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9795918367346939\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('tips.csv')\n",
    "\n",
    "# Rest of your code\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 2: Prepare the data\n",
    "X = df['sex']\n",
    "y = pd.cut(df['tip'], bins=[0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50]).astype(str)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Vectorize the text data\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Step 4: Train the Naïve-Bayes classifier\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train_vectorized.toarray(), y_train)\n",
    "\n",
    "# Step 5: Evaluate the classifier\n",
    "y_pred = nb_classifier.predict(X_test_vectorized.toarray())\n",
    "accuracy = (y_pred == y_test).mean()\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12582dcd-0386-469e-9947-9cbcdeb206c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "df = pd.read_csv('lab_4.csv')\n",
    "\n",
    "# Step 2: Prepare the data\n",
    "X = df['income']\n",
    "y = df['student']\n",
    "\n",
    "# Step 3: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Vectorize the text data\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Step 5: Train the Naïve-Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Step 6: Evaluate the classifier\n",
    "accuracy = nb_classifier.score(X_test_vectorized, y_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200c459c-baa8-4e98-8955-07a3ef24484c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
